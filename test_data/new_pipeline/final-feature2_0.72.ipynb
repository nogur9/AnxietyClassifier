{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bartpy'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-13409417df8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbartpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearnmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSklearnModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bartpy'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from bartpy.sklearnmodel import SklearnModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveCorrelationTransformer2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, correlation_threshold=0.7):\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df_corr = df.corr(method='pearson', min_periods=1)\n",
    "        df_not_correlated = ~(df_corr.mask(\n",
    "            np.tril(np.ones([len(df_corr)] * 2, dtype=bool))).abs() > self.correlation_threshold).any()\n",
    "        self.un_corr_idx = df_not_correlated.loc[df_not_correlated[df_not_correlated.index] == True].index\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df = df[self.un_corr_idx]\n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RemoveCorrelationTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, correlation_threshold=0.7, pca_components_ratio=3):\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "        self.pca_components_ratio = pca_components_ratio\n",
    "\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df_corr = df.corr(method='pearson')\n",
    "        df_corr = df_corr - np.eye(df.shape[1])\n",
    "        outliares_corr = df_corr[np.abs(df_corr) > self.correlation_threshold]\n",
    "        self.outliares_corr = outliares_corr.dropna(axis=1, how='all')\n",
    "\n",
    "        correlated_df = df[self.outliares_corr.columns]\n",
    "\n",
    "        n_components = len(self.outliares_corr.columns) // self.pca_components_ratio\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "        correlated_df = pca.fit_transform(correlated_df)\n",
    "        self.correlated_df = pd.DataFrame(correlated_df, columns=[\"pca_{}\".format(i) for i in range(n_components)])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df = df.drop((self.outliares_corr.columns), axis=1)\n",
    "        df = df.join(self.correlated_df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RemoveMissingFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        self.is_missing = X.isnull().values.any(axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        copy_x = pd.DataFrame(X)\n",
    "        self.is_missing += copy_x.isnull().values.any(axis=0)\n",
    "\n",
    "        copy_x = copy_x.iloc[:, ~self.is_missing]\n",
    "\n",
    "        return copy_x.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_labels(df):\n",
    "    return df.replace({'low': 0 ,'high': 1, 'clinical': 1 })\n",
    "\n",
    "\n",
    "def get_data(file_name, LSAS_threshold=None):\n",
    "    group_column = 'group'\n",
    "    sub_num_col = 'Subject_Number'\n",
    "    lsas_col = 'LSAS'\n",
    "    df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "    if LSAS_threshold is None:\n",
    "        X = df.drop([group_column, sub_num_col, lsas_col], 1)\n",
    "        Y = refactor_labels(df[group_column])\n",
    "        return X, Y\n",
    "    else:\n",
    "        X = df.drop([group_column], 1)\n",
    "        Y = pd.Series(np.where(X[lsas_col] > LSAS_threshold, 1, 0))\n",
    "        X = X.drop([sub_num_col, lsas_col], 1)\n",
    "        return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lists_ver2 = [\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"training_set_100.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ecca4447c6ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSAS_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_data' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "X_train, y_train = get_data(file_name, LSAS_threshold = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(217828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['avg_of_sum_fixation_length_Disgusted',\n",
       "       'avg_of_sum_fixation_length_Neutral',\n",
       "       'avg_of_sum_fixation_length_White_Space',\n",
       "       'average_fixation_length_Disgusted', 'average_fixation_length_Neutral',\n",
       "       'average_fixation_length_White_Space',\n",
       "       'avg_of_amount_fixation_Disgusted', 'avg_of_amount_fixation_Neutral',\n",
       "       'avg_of_amount_fixation_White_Space', 'STD_fixation_length_Disgusted',\n",
       "       'STD_fixation_length_Neutral', 'STD_fixation_length_White_Space',\n",
       "       'STD_fixation_length_All', 'Ratio D/D+N', 'Ratio N/D+N',\n",
       "       'var_ratio_D_DN', 'average_pupil_size_Disgusted',\n",
       "       'average_pupil_size_Neutral', 'average_pupil_size_White_Space',\n",
       "       'average_pupil_size_All', 'STD_pupil_size_Disgusted',\n",
       "       'STD_pupil_size_Neutral', 'STD_pupil_size_White_Space',\n",
       "       'STD_pupil_size_All', 'mean_different_AOI_per_trial'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_shuffled = list(features_lists_ver2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(columns_shuffled)\n",
    "X_train = X_train[columns_shuffled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_train, y_train, test_size = 0.1, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"full_test_set.xlsx\"\n",
    "df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "X_test = df.drop('Subject_Number', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training pipeline\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe =  Pipeline([\n",
    "    (\"rnf\", RemoveMissingFeaturesTransformer()), \n",
    "    ('correlation_threshold', RemoveCorrelationTransformer2()), \n",
    "    ('rfc', RFE(RandomForestClassifier(n_estimators = 100))),\n",
    "    ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = [\n",
    "    {\n",
    "        'correlation_threshold__correlation_threshold' : [0.8],\n",
    "        'rfc__n_features_to_select': [8,6],\n",
    "        'classifier__min_child_weight': [1],\n",
    "        'classifier__gamma': np.arange(0.2,1, 0.3),\n",
    "        'classifier__subsample': [0.99, 0.9],\n",
    "        'classifier__colsample_bytree': [0.7],\n",
    "        'classifier__max_depth': [3, 2, 5],\n",
    "        'classifier__reg_alpha' : [0.5],\n",
    "        'classifier__reg_lambda' :  [0.2],\n",
    "        'classifier__learning_rate': [0.05, 0.1],\n",
    "        'classifier__n_estimators': [ 70, 95, 150, 250]}] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=LeaveOneOut(), error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('rnf', RemoveMissingFeaturesTransformer()), ('correlation_threshold', RemoveCorrelationTransformer2(correlation_threshold=0.7)), ('rfc', RFE(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=N...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'correlation_threshold__correlation_threshold': [0.8], 'rfc__n_features_to_select': [8, 6], 'classifier__min_child_weight': [1], 'classifier__gamma': array([0.2, 0.5, 0.8]), 'classifier__subsample': [0.99, 0.9], 'classifier__colsample_bytree': [0.7], 'classifier__max_depth': [3, 2, 5], 'classifier__reg_alpha': [0.5], 'classifier__reg_lambda': [0.2], 'classifier__learning_rate': [0.05, 0.1], 'classifier__n_estimators': [70, 95, 150, 250]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = LeaveOneOut()\n",
    "gs = GridSearchCV(pipe, params_grid, cv=cv, scoring='accuracy')\n",
    "gs.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__colsample_bytree': 0.7,\n",
       " 'classifier__gamma': 0.5,\n",
       " 'classifier__learning_rate': 0.05,\n",
       " 'classifier__max_depth': 5,\n",
       " 'classifier__min_child_weight': 1,\n",
       " 'classifier__n_estimators': 70,\n",
       " 'classifier__reg_alpha': 0.5,\n",
       " 'classifier__reg_lambda': 0.2,\n",
       " 'classifier__subsample': 0.99,\n",
       " 'correlation_threshold__correlation_threshold': 0.8,\n",
       " 'rfc__n_features_to_select': 8}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validate grid search score LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7222222222222218"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "k = 30\n",
    "for i in range(k):\n",
    "    loo = LeaveOneOut()\n",
    "    score = cross_val_score(gs.best_estimator_, X_train_2, y_train_2, cv=loo)\n",
    "    results.append(score.mean())\n",
    "    print(i)\n",
    "sum(results)/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validate grid search score  10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7338888888888885"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "k = 30\n",
    "for i in range(k):\n",
    "    cv = StratifiedKFold(10)\n",
    "    score = cross_val_score(gs.best_estimator_, X_train_2, y_train_2, cv=cv)\n",
    "    results.append(score.mean())\n",
    "    print(i)\n",
    "sum(results)/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gs.best_estimator_.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scores on full set LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "k = 30\n",
    "for i in range(k):\n",
    "    loo = LeaveOneOut()\n",
    "    score = cross_val_score(gs.best_estimator_, X_train, y_train, cv=loo)\n",
    "    results.append(score.mean())\n",
    "    print(i)\n",
    "sum(results)/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scores on full set 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6265656565656564"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "k = 30\n",
    "for i in range(k):\n",
    "    cv = StratifiedKFold(10)\n",
    "    score = cross_val_score(gs.best_estimator_, X_train, y_train, cv=cv)\n",
    "    results.append(score.mean())\n",
    "    print(i)\n",
    "sum(results)/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
