{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wide search, 2 best feature sets, corr and RFE & hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveCorrelationTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, correlation_threshold=0.7):\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df_corr = df.corr(method='pearson', min_periods=1)\n",
    "        df_not_correlated = ~(df_corr.mask(\n",
    "            np.tril(np.ones([len(df_corr)] * 2, dtype=bool))).abs() > self.correlation_threshold).any()\n",
    "        self.un_corr_idx = df_not_correlated.loc[df_not_correlated[df_not_correlated.index] == True].index\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df = df[self.un_corr_idx]\n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RemoveCorrelationTransformerWithPCA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, correlation_threshold=0.7, pca_components_ratio=3):\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "        self.pca_components_ratio = pca_components_ratio\n",
    "\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df_corr = df.corr(method='pearson')\n",
    "        df_corr = df_corr - np.eye(df.shape[1])\n",
    "        outliares_corr = df_corr[np.abs(df_corr) > self.correlation_threshold]\n",
    "        self.outliares_corr = outliares_corr.dropna(axis=1, how='all')\n",
    "\n",
    "        correlated_df = df[self.outliares_corr.columns]\n",
    "\n",
    "        n_components = len(self.outliares_corr.columns) // self.pca_components_ratio\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "        correlated_df = pca.fit_transform(correlated_df)\n",
    "        self.correlated_df = pd.DataFrame(correlated_df, columns=[\"pca_{}\".format(i) for i in range(n_components)])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df = df.drop((self.outliares_corr.columns), axis=1)\n",
    "        df = df.join(self.correlated_df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveMissingFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        self.is_missing = X.isnull().values.any(axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        copy_x = pd.DataFrame(X)\n",
    "        self.is_missing += copy_x.isnull().values.any(axis=0)\n",
    "\n",
    "        copy_x = copy_x.iloc[:, ~self.is_missing]\n",
    "\n",
    "        return copy_x.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_labels(df):\n",
    "    return df.replace({'low': 0 ,'high': 1, 'clinical': 1 })\n",
    "\n",
    "\n",
    "def get_data(file_name, LSAS_threshold=None):\n",
    "    group_column = 'group'\n",
    "    sub_num_col = 'Subject_Number'\n",
    "    lsas_col = 'LSAS'\n",
    "    df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "    if LSAS_threshold is None:\n",
    "        X = df.drop([group_column, sub_num_col, lsas_col], 1)\n",
    "        Y = refactor_labels(df[group_column])\n",
    "        return X, Y\n",
    "    else:\n",
    "        X = df.drop([group_column], 1)\n",
    "        Y = pd.Series(np.where(X[lsas_col] > LSAS_threshold, 1, 0))\n",
    "        X = X.drop([sub_num_col, lsas_col], 1)\n",
    "        return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from random features copy 7\n",
    "features_lists_ = [\n",
    "['STD_fixation_length_White_Space', 'STD_pupil_size_Neutral', 'STD_pupil_size_White_Space', 'average_fixation_length_Neutral', 'avg_of_amount_fixation_Disgusted', 'average_pupil_size_White_Space', 'STD_fixation_length_Neutral', 'Ratio D/D+N', 'avg_of_sum_fixation_length_Disgusted', 'avg_of_amount_fixation_Neutral', 'average_pupil_size_Disgusted', 'avg_of_sum_fixation_length_Neutral', 'var_ratio_D_DN', 'average_fixation_length_White_Space'],\n",
    "['avg_of_amount_fixation_Disgusted', 'average_pupil_size_Disgusted', 'STD_pupil_size_Neutral', 'average_fixation_length_Neutral', 'Ratio D/D+N', 'avg_of_sum_fixation_length_Neutral', 'STD_fixation_length_Neutral', 'average_pupil_size_White_Space', 'avg_of_amount_fixation_Neutral', 'STD_fixation_length_White_Space', 'average_fixation_length_White_Space', 'avg_of_sum_fixation_length_Disgusted', 'var_ratio_D_DN', 'STD_pupil_size_White_Space']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"training_set_100.xlsx\"\n",
    "X_full_training_set, y_full_training_set = get_data(file_name, LSAS_threshold = 50)\n",
    "random.seed(217828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe =  Pipeline([\n",
    "        ('correlation_threshold', RemoveCorrelationTransformer()), \n",
    "    ('rfc', RFE(RandomForestClassifier(n_estimators = 100))),\n",
    "    ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = [\n",
    "    {\n",
    "        #'correlation_threshold':[RemoveCorrelationTransformer(), RemoveCorrelationTransformerWithPCA()],\n",
    "       'correlation_threshold__correlation_threshold' : [0.8, 1],\n",
    "        'rfc__n_features_to_select': [10,12,14, 18],\n",
    "        'classifier__min_child_weight': [1],\n",
    "        'classifier__gamma': [0.75],\n",
    "        'classifier__subsample': [0.9],\n",
    "        'classifier__colsample_bytree': [0.7],\n",
    "        'classifier__max_depth': [3, 2, 6],\n",
    "        'classifier__reg_alpha' : [0.5, 0.8],\n",
    "        'classifier__reg_lambda' :  [ 0.1,0.5],\n",
    "        'classifier__learning_rate': [0.1,0.05],\n",
    "        'classifier__n_estimators': [ 190, 125, 300, 60]}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(feature_set, X_full_training_set, y_full_training_set):\n",
    "    columns_shuffled = list(feature_set)\n",
    "    random.shuffle(columns_shuffled)\n",
    "    X_full_training_set = X_full_training_set[columns_shuffled] \n",
    "    X_train, X_holdout, y_train, y_holdout = train_test_split(X_full_training_set, y_full_training_set, \n",
    "                                                              test_size = 0.1, stratify=y_full_training_set)\n",
    "    return X_train, X_holdout, y_train, y_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_over_k_runs(k, cv,  X, y, best_estimator_):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        score = cross_val_score(best_estimator_, X, y, cv=cv)\n",
    "        results.append(score.mean())\n",
    "        \n",
    "    print(sum(results)/k)\n",
    "    return (sum(results)/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_generalization(pipe, params_grid, X_train, X_full_training_set, X_holdout,\n",
    "                         y_train, y_full_training_set, y_holdout, k=100):\n",
    "    \n",
    "    cv = LeaveOneOut()#StratifiedKFold(10)\n",
    "    gs = GridSearchCV(pipe, params_grid, cv=cv, scoring='accuracy')\n",
    "    gs.fit(X_full_training_set, y_full_training_set)\n",
    "    print(\"gs best score\", gs.best_score_)\n",
    "    print(\"gs best params\", gs.best_params_)\n",
    "    \n",
    "    model = gs.best_estimator_.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_holdout)\n",
    "    holdout_acc = accuracy_score(y_pred, y_holdout)\n",
    "    print(\"accuracy score\", holdout_acc)\n",
    "    \n",
    "    taining_set_cv = check_over_k_runs(k, LeaveOneOut(),  X_train, y_train, gs.best_estimator_)\n",
    "    full_set_cv = check_over_k_runs(k, LeaveOneOut(),  X_full_training_set, y_full_training_set, gs.best_estimator_)\n",
    "    model = gs.best_estimator_.fit(X_full_training_set, y_full_training_set)\n",
    "    save_model(holdout_acc, taining_set_cv, full_set_cv, gs.best_estimator_.fit(X_full_training_set, y_full_training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(holdout_acc, taining_set_cv, full_set_cv, model):\n",
    "    if (holdout_acc >= 0.6) & (taining_set_cv > 0.6) & (full_set_cv > 0.67):\n",
    "        print(\"saving model\")\n",
    "        filename = \"model_copy3.pkl\"\n",
    "        pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STD_fixation_length_White_Space', 'STD_pupil_size_Neutral', 'STD_pupil_size_White_Space', 'average_fixation_length_Neutral', 'avg_of_amount_fixation_Disgusted', 'average_pupil_size_White_Space', 'STD_fixation_length_Neutral', 'Ratio D/D+N', 'avg_of_sum_fixation_length_Disgusted', 'avg_of_amount_fixation_Neutral', 'average_pupil_size_Disgusted', 'avg_of_sum_fixation_length_Neutral', 'var_ratio_D_DN', 'average_fixation_length_White_Space'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature_set in features_lists_:\n",
    "    print (feature_set, \"\\n\")\n",
    "    \n",
    "    X_train, X_holdout, y_train, y_holdout = split_data(feature_set, X_full_training_set, y_full_training_set)\n",
    "    check_generalization(pipe,  params_grid, X_train, X_full_training_set, X_holdout,\n",
    "                         y_train, y_full_training_set, y_holdout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dd_756 ff751'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"dd_{} ff{}\".format(int(0.756818*1000), int(0.7512*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
