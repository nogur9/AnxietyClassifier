{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveCorrelationTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, correlation_threshold=0.7):\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df_corr = df.corr(method='pearson', min_periods=1)\n",
    "        df_not_correlated = ~(df_corr.mask(\n",
    "            np.tril(np.ones([len(df_corr)] * 2, dtype=bool))).abs() > self.correlation_threshold).any()\n",
    "        self.un_corr_idx = df_not_correlated.loc[df_not_correlated[df_not_correlated.index] == True].index\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df = df[self.un_corr_idx]\n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RemoveCorrelationTransformerWithPCA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, correlation_threshold=0.8, pca_components_ratio=1):\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "        self.pca_components_ratio = pca_components_ratio\n",
    "\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df_corr = df.corr(method='pearson')\n",
    "        df_corr = df_corr - np.eye(df.shape[1])\n",
    "        outliares_corr = df_corr[np.abs(df_corr) > self.correlation_threshold]\n",
    "        self.outliares_corr = outliares_corr.dropna(axis=1, how='all')\n",
    "\n",
    "        correlated_df = df[self.outliares_corr.columns]\n",
    "\n",
    "        n_components = len(self.outliares_corr.columns) // self.pca_components_ratio\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "        correlated_df = pca.fit_transform(correlated_df)\n",
    "        self.correlated_df = pd.DataFrame(correlated_df, columns=[\"pca_{}\".format(i) for i in range(n_components)])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        df = pd.DataFrame(X)\n",
    "        df = df.drop((self.outliares_corr.columns), axis=1)\n",
    "        df = df.join(self.correlated_df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveMissingFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        self.is_missing = X.isnull().values.any(axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        copy_x = pd.DataFrame(X)\n",
    "        self.is_missing += copy_x.isnull().values.any(axis=0)\n",
    "\n",
    "        copy_x = copy_x.iloc[:, ~self.is_missing]\n",
    "\n",
    "        return copy_x.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_labels(df):\n",
    "    return df.replace({'low': 0 ,'high': 1, 'clinical': 1 })\n",
    "\n",
    "\n",
    "def get_data(file_name, LSAS_threshold=None):\n",
    "    group_column = 'group'\n",
    "    sub_num_col = 'Subject_Number'\n",
    "    lsas_col = 'LSAS'\n",
    "    df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "    if LSAS_threshold is None:\n",
    "        X = df.drop([group_column, sub_num_col, lsas_col], 1)\n",
    "        Y = refactor_labels(df[group_column])\n",
    "        return X, Y\n",
    "    else:\n",
    "        X = df.drop([group_column], 1)\n",
    "        Y = pd.Series(np.where(X[lsas_col] > LSAS_threshold, 1, 0))\n",
    "        X = X.drop([sub_num_col, lsas_col], 1)\n",
    "        return X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"training set cutoff 30.xlsx\"\n",
    "X_full_training_set, y_full_training_set = get_data(file_name, LSAS_threshold = 50)\n",
    "random.seed(217828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe =  Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('correlation_threshold', RemoveCorrelationTransformer()), \n",
    "   ('rfc', RFE(RandomForestClassifier(n_estimators = 100))),\n",
    "    ('classifier', GradientBoostingClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = [\n",
    "    {\n",
    "       'correlation_threshold__correlation_threshold':[0.9],\n",
    "        'rfc__n_features_to_select': [13],\n",
    "            \"classifier__min_samples_split\": [7],\n",
    "        'classifier__max_depth': [3],\n",
    "        'classifier__learning_rate': [0.15],\n",
    "        'classifier__n_estimators': [400]}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(feature_set, X_full_training_set, y_full_training_set):\n",
    "    columns_shuffled = list(X_full_training_set.columns)\n",
    "    random.shuffle(columns_shuffled)\n",
    "    X_full_training_set = X_full_training_set[columns_shuffled] \n",
    "    X_train, X_holdout, y_train, y_holdout = train_test_split(X_full_training_set, y_full_training_set, \n",
    "                                                              test_size = 0.1, stratify=y_full_training_set)\n",
    "    return X_train, X_holdout, y_train, y_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_over_k_runs(k, cv,  X, y, best_estimator_):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        score = cross_val_score(best_estimator_, X, y, cv=cv)\n",
    "        results.append(score.mean())\n",
    "        \n",
    "    print(sum(results)/k)\n",
    "    return (sum(results)/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_generalization(pipe, params_grid, X_train, X_full_training_set, X_holdout,\n",
    "                         y_train, y_full_training_set, y_holdout, k=100):\n",
    "    \n",
    "    cv = LeaveOneOut()#StratifiedKFold(10)#LeaveOneOut()#\n",
    "    gs = GridSearchCV(pipe, params_grid, cv=cv, scoring='accuracy')\n",
    "    gs.fit(X_full_training_set, y_full_training_set)\n",
    "    print(\"gs best score\", gs.best_score_)\n",
    "    print(\"gs best params\", gs.best_params_)\n",
    "    \n",
    "    model = gs.best_estimator_.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_holdout)\n",
    "\n",
    "    holdout_acc = accuracy_score(y_pred, y_holdout)\n",
    "    print(\"accuracy score\", holdout_acc)\n",
    "    \n",
    "    taining_set_cv = check_over_k_runs(k, LeaveOneOut(),  X_train, y_train, gs.best_estimator_)\n",
    "    full_set_cv = check_over_k_runs(k, LeaveOneOut(),  X_full_training_set, y_full_training_set, gs.best_estimator_)\n",
    "    save_model(holdout_acc, taining_set_cv, full_set_cv, gs.best_estimator_.fit(X_full_training_set, y_full_training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(holdout_acc, training_set_cv, full_set_cv, model):\n",
    "    if (holdout_acc > 0.6) & (training_set_cv > 0.6) & (full_set_cv > 0.67):\n",
    "        filename = 'finalized_model_holdout_acc_{} taining_set_cv_{} full_set_cv_{}.sav'.format\n",
    "        (int(holdout_acc*1000),int(training_set_cv*1000),int(full_set_cv*1000))\n",
    "        pickle.dump(model, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs best score 0.8125\n",
      "gs best params {'classifier__learning_rate': 0.15, 'classifier__max_depth': 3, 'classifier__min_samples_split': 7, 'classifier__n_estimators': 400, 'correlation_threshold__correlation_threshold': 0.9, 'rfc__n_features_to_select': 13}\n",
      "accuracy score 0.9\n",
      "0.7067441860465117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#X, X_2, y, y_2 = train_test_split(X_full_training_set, y_full_training_set, test_size = 0.04, stratify=y_full_training_set)\n",
    "X_train, X_holdout, y_train, y_holdout = split_data(X_full_training_set.columns, X_full_training_set, y_full_training_set)\n",
    "check_generalization(pipe,  params_grid, X_train, X_full_training_set, X_holdout,\n",
    "                         y_train, y_full_training_set, y_holdout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "? GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
